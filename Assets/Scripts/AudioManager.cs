using System;
using System.Collections;
using UnityEngine;

/// <summary>
/// éŸ³å£°éŒ²éŸ³ãƒ»å†ç”Ÿã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹
/// ãƒã‚¤ã‚¯éŸ³å£° â†’ PCM16å¤‰æ› â†’ ãƒãƒ£ãƒ³ã‚¯é€ä¿¡
/// å—ä¿¡éŸ³å£° â†’ AudioClipå¤‰æ› â†’ é€£ç¶šå†ç”Ÿ
/// </summary>
public class AudioManager : MonoBehaviour
{
    [Header("éŸ³å£°è¨­å®š")]
    [SerializeField] private int sampleRate = 16000; // âœ… OpenAI Realtime APIæ¨™æº–ä»•æ§˜
    [SerializeField] private float chunkDurationMs = 50f; // 50msãƒãƒ£ãƒ³ã‚¯
    [SerializeField] private int recordingLength = 10; // å¾ªç’°ãƒãƒƒãƒ•ã‚¡é•·(ç§’)
    
    [Header("å¿…é ˆã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ")]
    [SerializeField] private AudioSource audioSource;
    
    [Header("ãƒ‡ãƒãƒƒã‚°")]
    [SerializeField] private bool showDebugLog = true;
    
    // ãƒã‚¤ã‚¯é–¢é€£
    private AudioClip microphoneClip;
    private string microphoneDevice;
    private bool isRecording = false;
    private Coroutine recordingCoroutine;
    
    // ğŸµ éŸ³å£°å†ç”Ÿãƒãƒƒãƒ•ã‚¡ï¼ˆãƒªãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡æ–¹å¼ï¼‰
    private AudioClip streamingClip;
    private float[] audioBuffer;
    private int bufferWritePosition = 0;
    private int bufferReadPosition = 0;  // â† ã“ã‚Œã‚’è¿½åŠ 
    private int bufferSize;
    private bool isStreaming = false;
    
    // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆ
    public event Action<byte[]> OnAudioChunkReady;
    
    // ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    public bool IsRecording => isRecording;
    public int SampleRate => sampleRate;
    
    #region Unity Lifecycle
    
    private void Awake()
    {
        // AudioSourceç¢ºä¿
        if (audioSource == null)
        {
            audioSource = GetComponent<AudioSource>();
            if (audioSource == null)
            {
                audioSource = gameObject.AddComponent<AudioSource>();
            }
        }
        
        // âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–
        InitializeStreamingBuffer();
    }
    
    private void Start()
    {
        InitializeMicrophone();
    }
    
    private void OnDestroy()
    {
        StopRecording();
        StopStreaming();
    }
    
    #endregion
    
    #region ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ãƒãƒƒãƒ•ã‚¡
    
    /// <summary>
    /// ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã®åˆæœŸåŒ–
    /// </summary>
    private void InitializeStreamingBuffer()
    {
        // 3ç§’åˆ†ã®ãƒãƒƒãƒ•ã‚¡ã‚’ç”¨æ„ï¼ˆ16kHz Ã— 3ç§’ï¼‰
        bufferSize = sampleRate * 3;
        audioBuffer = new float[bufferSize];
        
        // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨AudioClipä½œæˆ
        streamingClip = AudioClip.Create(
            "StreamingAudio",
            bufferSize,
            1, // ãƒ¢ãƒãƒ©ãƒ«
            sampleRate,
            true, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
            OnAudioRead
        );
        
        LogDebug($"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡åˆæœŸåŒ–: {bufferSize} samples ({bufferSize / (float)sampleRate:F1}ç§’)");
    }
    
    /// <summary>
    /// AudioClipã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    /// </summary>
    /// <param name="data">å‡ºåŠ›éŸ³å£°ãƒ‡ãƒ¼ã‚¿</param>
    private void OnAudioRead(float[] data)
{
    if (!isStreaming || audioBuffer == null)
    {
        // ç„¡éŸ³ã§åŸ‹ã‚ã‚‹
        for (int i = 0; i < data.Length; i++)
        {
            data[i] = 0f;
        }
        return;
    }
    
    lock (_streamLock)
    {
        // ã‚·ãƒ³ãƒ—ãƒ«ãªèª­ã¿å–ã‚Š
        for (int i = 0; i < data.Length; i++)
        {
            data[i] = audioBuffer[bufferReadPosition] * 0.3f; // éŸ³é‡ã‚’30%ã«
            bufferReadPosition = (bufferReadPosition + 1) % bufferSize;
        }
    }
}
    
    /// <summary>
    /// ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹
    /// </summary>
    private void StartStreaming()
{
    if (!isStreaming && streamingClip != null)
    {
        isStreaming = true;
        audioSource.clip = streamingClip;
        audioSource.loop = true;
        audioSource.volume = 0.5f;  // â† éŸ³é‡ã‚’50%ã«
        audioSource.Play();
        LogDebug($"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°é–‹å§‹ - SampleRate: {streamingClip.frequency}Hz");
    }
}
    
    /// <summary>
    /// ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åœæ­¢
    /// </summary>
    private void StopStreaming()
    {
        if (isStreaming)
        {
            isStreaming = false;
            audioSource.Stop();
            audioSource.clip = null;
            LogDebug("ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°åœæ­¢");
        }
    }
    
    #endregion
    
    #region ãƒã‚¤ã‚¯åˆæœŸåŒ–
    
    /// <summary>
    /// ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ã®åˆæœŸåŒ–
    /// </summary>
    private void InitializeMicrophone()
    {
        if (Microphone.devices.Length > 0)
        {
            microphoneDevice = Microphone.devices[0];
            LogDebug($"ä½¿ç”¨ãƒã‚¤ã‚¯: {microphoneDevice}");
        }
        else
        {
            LogError("ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“");
            microphoneDevice = null;
        }
    }
    
    #endregion
    
    #region éŒ²éŸ³åˆ¶å¾¡
    
    /// <summary>
    /// éŒ²éŸ³é–‹å§‹
    /// </summary>
    public void StartRecording()
    {
        if (isRecording)
        {
            LogDebug("æ—¢ã«éŒ²éŸ³ä¸­ã§ã™");
            return;
        }
        
        if (string.IsNullOrEmpty(microphoneDevice))
        {
            LogError("ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“");
            return;
        }
        
        try
        {
            // ãƒã‚¤ã‚¯éŒ²éŸ³é–‹å§‹
            microphoneClip = Microphone.Start(microphoneDevice, true, recordingLength, sampleRate);
            
            if (microphoneClip == null)
            {
                LogError("ãƒã‚¤ã‚¯éŒ²éŸ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ");
                return;
            }
            
            isRecording = true;
            
            // éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡ã‚³ãƒ«ãƒ¼ãƒãƒ³é–‹å§‹
            recordingCoroutine = StartCoroutine(SendAudioChunks());
            
            LogDebug("éŒ²éŸ³é–‹å§‹æˆåŠŸ");
        }
        catch (Exception e)
        {
            LogError($"éŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼: {e.Message}");
        }
    }
    
    /// <summary>
    /// éŒ²éŸ³åœæ­¢
    /// </summary>
    public void StopRecording()
    {
        if (!isRecording)
        {
            return;
        }
        
        isRecording = false;
        
        // ã‚³ãƒ«ãƒ¼ãƒãƒ³åœæ­¢
        if (recordingCoroutine != null)
        {
            StopCoroutine(recordingCoroutine);
            recordingCoroutine = null;
        }
        
        // ãƒã‚¤ã‚¯åœæ­¢
        if (!string.IsNullOrEmpty(microphoneDevice))
        {
            Microphone.End(microphoneDevice);
        }
        
        LogDebug("éŒ²éŸ³åœæ­¢");
    }
    
    #endregion
    
    #region éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡
    
    /// <summary>
    /// éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å®šæœŸçš„ã«é€ä¿¡ã™ã‚‹ã‚³ãƒ«ãƒ¼ãƒãƒ³
    /// </summary>
    private IEnumerator SendAudioChunks()
    {
        int lastSample = 0;
        int samplesPerChunk = Mathf.RoundToInt(sampleRate * (chunkDurationMs / 1000f));
        float waitTime = chunkDurationMs / 1000f;
        
        // âœ… 16kHz Ã— 50ms = 800ã‚µãƒ³ãƒ—ãƒ« Ã— 2bytes = 1600 bytesæœŸå¾…
        LogDebug($"ãƒãƒ£ãƒ³ã‚¯é€ä¿¡é–‹å§‹ - ã‚µãƒ³ãƒ—ãƒ«/ãƒãƒ£ãƒ³ã‚¯: {samplesPerChunk}, æœŸå¾…ãƒã‚¤ãƒˆæ•°: {samplesPerChunk * 2}, é–“éš”: {waitTime:F3}ç§’");
        
        while (isRecording && microphoneClip != null)
        {
            try
            {
                int currentSample = Microphone.GetPosition(microphoneDevice);
                
                // å¾ªç’°ãƒãƒƒãƒ•ã‚¡ã®å‡¦ç†
                if (currentSample < lastSample)
                {
                    // ãƒãƒƒãƒ•ã‚¡ãŒå¾ªç’°ã—ãŸå ´åˆã€æ®‹ã‚Šã®éƒ¨åˆ†ã‚’å‡¦ç†
                    int remainingSamples = microphoneClip.samples - lastSample;
                    if (remainingSamples > 0)
                    {
                        ProcessAudioChunk(lastSample, remainingSamples);
                    }
                    lastSample = 0;
                }
                
                // æ–°ã—ã„ã‚µãƒ³ãƒ—ãƒ«ã‚’å‡¦ç†
                if (currentSample > lastSample)
                {
                    int availableSamples = currentSample - lastSample;
                    
                    while (availableSamples >= samplesPerChunk)
                    {
                        ProcessAudioChunk(lastSample, samplesPerChunk);
                        lastSample += samplesPerChunk;
                        availableSamples -= samplesPerChunk;
                    }
                }
            }
            catch (Exception e)
            {
                LogError($"éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e.Message}");
            }
            
            yield return new WaitForSeconds(waitTime);
        }
        
        LogDebug("ãƒãƒ£ãƒ³ã‚¯é€ä¿¡çµ‚äº†");
    }
    
    /// <summary>
    /// æŒ‡å®šä½ç½®ã‹ã‚‰éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†
    /// </summary>
    private void ProcessAudioChunk(int startSample, int sampleCount)
    {
        try
        {
            // éŸ³å£°ã‚µãƒ³ãƒ—ãƒ«å–å¾—
            float[] samples = new float[sampleCount];
            microphoneClip.GetData(samples, startSample);
            
            // PCM16ã«å¤‰æ›
            byte[] pcmData = ConvertToPCM16(samples);
            
            if (pcmData.Length > 0)
            {
                // ã‚¤ãƒ™ãƒ³ãƒˆé€šçŸ¥ã§é€ä¿¡
                OnAudioChunkReady?.Invoke(pcmData);
                LogDebug($"éŸ³å£°ãƒãƒ£ãƒ³ã‚¯é€ä¿¡: {pcmData.Length} bytes"); // 1600 bytesæœŸå¾…
            }
        }
        catch (Exception e)
        {
            LogError($"éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e.Message}");
        }
    }
    
    #endregion
    
    #region éŸ³å£°å¤‰æ›
    
    /// <summary>
    /// Unity floaté…åˆ—ã‚’PCM16ãƒã‚¤ãƒˆé…åˆ—ã«å¤‰æ›
    /// </summary>
    private byte[] ConvertToPCM16(float[] samples)
    {
        byte[] pcmData = new byte[samples.Length * 2];
        
        for (int i = 0; i < samples.Length; i++)
        {
            // UnityéŸ³å£°ç¯„å›² (-1.0f ~ 1.0f) ã‚’PCM16ç¯„å›² (-32768 ~ 32767) ã«å¤‰æ›
            float clampedSample = Mathf.Clamp(samples[i], -1.0f, 1.0f);
            short pcm16Sample = (short)(clampedSample * 32767f);
            
            // Little Endianå½¢å¼ã§ãƒã‚¤ãƒˆé…åˆ—ã«æ ¼ç´
            pcmData[i * 2] = (byte)(pcm16Sample & 0xFF);           // ä¸‹ä½ãƒã‚¤ãƒˆ
            pcmData[i * 2 + 1] = (byte)((pcm16Sample >> 8) & 0xFF); // ä¸Šä½ãƒã‚¤ãƒˆ
        }
        
        return pcmData;
    }
    
    /// <summary>
    /// PCM16ãƒã‚¤ãƒˆé…åˆ—ã‚’Unity floaté…åˆ—ã«å¤‰æ›
    /// </summary>
    private float[] ConvertFromPCM16(byte[] pcmData)
    {
        if (pcmData.Length % 2 != 0)
        {
            LogError("ç„¡åŠ¹ãªPCM16ãƒ‡ãƒ¼ã‚¿: ãƒã‚¤ãƒˆæ•°ãŒå¥‡æ•°ã§ã™");
            return new float[0];
        }
        
        int sampleCount = pcmData.Length / 2;
        float[] samples = new float[sampleCount];
        
        for (int i = 0; i < sampleCount; i++)
        {
            // Little Endianãƒã‚¤ãƒˆé…åˆ—ã‹ã‚‰shortã«å¤‰æ›
            short pcm16Sample = (short)(pcmData[i * 2] | (pcmData[i * 2 + 1] << 8));
            
            // PCM16ç¯„å›²ã‚’Unityç¯„å›²ã«å¤‰æ›
            samples[i] = pcm16Sample / 32768f;
        }
        
        return samples;
    }
    
    #endregion
    
    #region éŸ³å£°å†ç”Ÿ
    
/// <summary>
/// å—ä¿¡ã—ãŸéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å†ç”Ÿï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ–¹å¼ï¼‰
/// </summary>
public void PlayReceivedAudio(byte[] audioData)
{
    if (audioData == null || audioData.Length == 0)
    {
        LogDebug("ç©ºã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯å†ç”Ÿã—ã¾ã›ã‚“");
        return;
    }
    
    try
    {
        // AudioSourceãƒã‚§ãƒƒã‚¯
        if (audioSource == null)
        {
            LogError("AudioSourceãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼");
            return;
        }
        
        // PCM16ãƒ‡ãƒ¼ã‚¿ã‚’floaté…åˆ—ã«å¤‰æ›
        float[] samples = ConvertFromPCM16(audioData);
        
        if (samples.Length == 0)
        {
            LogError("éŸ³å£°å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ");
            return;
        }
        
        // éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        float maxAmplitude = 0f;
        float avgAmplitude = 0f;
        for (int i = 0; i < Mathf.Min(samples.Length, 1000); i++)
        {
            float abs = Mathf.Abs(samples[i]);
            maxAmplitude = Mathf.Max(maxAmplitude, abs);
            avgAmplitude += abs;
        }
        avgAmplitude /= Mathf.Min(samples.Length, 1000);
        
        LogDebug($"ğŸ“Š éŸ³å£°ãƒ¬ãƒ™ãƒ« - æœ€å¤§: {maxAmplitude:F4}, å¹³å‡: {avgAmplitude:F4}, ã‚µãƒ³ãƒ—ãƒ«æ•°: {samples.Length}");
        
        // AudioSourceã®çŠ¶æ…‹ç¢ºèª
        LogDebug($"ğŸ”Š AudioSourceçŠ¶æ…‹ - Volume: {audioSource.volume}, Mute: {audioSource.mute}, isPlaying: {audioSource.isPlaying}");
        
        // âœ… ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒãƒƒãƒ•ã‚¡ã«æ›¸ãè¾¼ã¿
        WriteToStreamingBuffer(samples);
        
        // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹ï¼ˆåˆå›ã®ã¿ï¼‰
        if (!isStreaming)
        {
            StartStreaming();
        }
        
        LogDebug($"âœ… éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {samples.Length} samples, {audioData.Length} bytes");
    }
    catch (Exception e)
    {
        LogError($"éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e.Message}\nStackTrace: {e.StackTrace}");
    }
}
    
    #endregion
    
    #region å…¬é–‹ãƒ¡ã‚½ãƒƒãƒ‰
    
    /// <summary>
    /// åˆ©ç”¨å¯èƒ½ãªãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’å–å¾—
    /// </summary>
    public string[] GetAvailableMicrophones()
    {
        return Microphone.devices;
    }
    
    /// <summary>
    /// ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ã‚’å¤‰æ›´
    /// </summary>
    public void ChangeMicrophoneDevice(int deviceIndex)
    {
        if (deviceIndex >= 0 && deviceIndex < Microphone.devices.Length)
        {
            bool wasRecording = isRecording;
            
            if (wasRecording)
            {
                StopRecording();
            }
            
            microphoneDevice = Microphone.devices[deviceIndex];
            LogDebug($"ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹å¤‰æ›´: {microphoneDevice}");
            
            if (wasRecording)
            {
                StartRecording();
            }
        }
    }
    
    /// <summary>
    /// éŸ³å£°è¨­å®šã‚’å‹•çš„ã«å¤‰æ›´
    /// </summary>
    public void ChangeAudioSettings(int newSampleRate, float newChunkDuration)
    {
        bool wasRecording = isRecording;
        
        if (wasRecording)
        {
            StopRecording();
        }
        
        sampleRate = newSampleRate;
        chunkDurationMs = newChunkDuration;
        
        LogDebug($"éŸ³å£°è¨­å®šå¤‰æ›´: {sampleRate}Hz, {chunkDurationMs}ms");
        
        if (wasRecording)
        {
            StartRecording();
        }
    }
    
    #endregion
    
    #region ãƒ‡ãƒãƒƒã‚°
    
    private void LogDebug(string message)
    {
        if (showDebugLog)
        {
            Debug.Log($"[AudioManager] {message}");
        }
    }
    
    private void LogError(string message)
    {
        Debug.LogError($"[AudioManager] {message}");
    }
    
    /// <summary>
    /// ç¾åœ¨ã®çŠ¶æ…‹æƒ…å ±ã‚’å–å¾—
    /// </summary>
    public string GetStatusInfo()
    {
        return $"éŒ²éŸ³: {isRecording}, ãƒã‚¤ã‚¯: {microphoneDevice ?? "ãªã—"}, ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°: {sampleRate}Hz, ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {isStreaming}";
    }
    
    #endregion

    [ContextMenu("Test Audio Playback")]
private void TestAudioPlayback()
{
    if (audioSource == null)
    {
        LogError("AudioSourceãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ï¼");
        return;
    }
    
    // AudioSourceã®è¨­å®šã‚’ç¢ºèª
    audioSource.volume = 1.0f;
    audioSource.mute = false;
    
    // ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µã‚¤ãƒ³æ³¢ã‚’ç”Ÿæˆï¼ˆ440Hzã€1ç§’ï¼‰
    float[] testSamples = new float[sampleRate];
    for (int i = 0; i < testSamples.Length; i++)
    {
        testSamples[i] = Mathf.Sin(2 * Mathf.PI * 440 * i / (float)sampleRate) * 0.5f;
    }
    
    // PCM16ã«å¤‰æ›ã—ã¦ã‹ã‚‰å†ç”Ÿ
    byte[] testPCM = ConvertToPCM16(testSamples);
    PlayReceivedAudio(testPCM);
    
    LogDebug($"ğŸµ ãƒ†ã‚¹ãƒˆéŸ³å£°ã‚’å†ç”Ÿã—ã¾ã—ãŸï¼ˆ440Hz, 1ç§’, {testPCM.Length} bytesï¼‰");
}

[ContextMenu("Check Audio System")]
private void CheckAudioSystem()
{
    LogDebug("=== Audio System Check ===");
    LogDebug($"AudioSource: {(audioSource != null ? "OK" : "NULL")}");
    
    if (audioSource != null)
    {
        LogDebug($"- Volume: {audioSource.volume}");
        LogDebug($"- Mute: {audioSource.mute}");
        LogDebug($"- isPlaying: {audioSource.isPlaying}");
        LogDebug($"- clip: {(audioSource.clip != null ? audioSource.clip.name : "NULL")}");
    }
    
    LogDebug($"StreamingClip: {(streamingClip != null ? "OK" : "NULL")}");
    LogDebug($"isStreaming: {isStreaming}");
    LogDebug($"Sample Rate: {sampleRate}");
    LogDebug($"Buffer Size: {bufferSize}");
    
    // Unityå…¨ä½“ã®éŸ³å£°è¨­å®š
    LogDebug($"Unity AudioListener Volume: {AudioListener.volume}");
    LogDebug($"Unity AudioListener Pause: {AudioListener.pause}");
}
}
