# mcp/app/routers/realtime.py - æ–¹å¼Bå®Œå…¨å®Ÿè£…ç‰ˆï¼ˆãƒãƒ¼ã‚¸ã‚¤ãƒ³å¯¾å¿œï¼‰

"""Unity â‡† OpenAI Realtime Audio API - æ–¹å¼Bï¼ˆæ‰‹å‹•åˆ¶å¾¡ï¼‹ãƒãƒ¼ã‚¸ã‚¤ãƒ³ï¼‰
----------------------------------------------------------------
ç‰¹å¾´:
1. create_response: False ã§è‡ªå‹•å¿œç­”ç”Ÿæˆã‚’ç„¡åŠ¹åŒ–
2. 20ãƒãƒ£ãƒ³ã‚¯ï¼ˆç´„1ç§’ï¼‰ã”ã¨ã«æ‰‹å‹•ã§commit + response.create
3. ãƒãƒ¼ã‚¸ã‚¤ãƒ³å¯¾å¿œ: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—å§‹ã‚ãŸã‚‰AIã®å¿œç­”ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
4. å¿œç­”ã®é‡è¤‡ã‚’å®Œå…¨ã«é˜²æ­¢
"""

from __future__ import annotations

import asyncio
import base64
import json
import logging
from typing import Any

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import websockets
from websockets.exceptions import ConnectionClosed, WebSocketException, InvalidStatusCode

from ..core.config import (
    get_websocket_url,
    OPENAI_API_KEY,
    SESSION_CONFIG,
    MODEL_NAME,
)
from ..services.function import handle_function

logger = logging.getLogger(__name__)
router = APIRouter()

# -----------------------------------------------------------------------------
# WebSocket relay
# -----------------------------------------------------------------------------

@router.websocket("/ws/audio")
async def relay(ws: WebSocket) -> None:  # noqa: C901
    """Unity â†” FastAPI â†” OpenAI realtime audio relay"""
    await ws.accept()
    logger.info("Unity WS connected: %s", id(ws))

    url = get_websocket_url()
    extra_headers = [
        ("Authorization", f"Bearer {OPENAI_API_KEY}"),
        ("OpenAI-Beta", "realtime=v1"),
    ]

    openai_ws: websockets.WebSocketClientProtocol | None = None

    try:
        # --------------------------- connect to OpenAI ------------------------
        openai_ws = await websockets.connect(
            url,
            extra_headers=extra_headers,
            ping_interval=None,   # ğŸ”• disable websocketâ€‘level ping
            ping_timeout=None,
            close_timeout=10,
        )
        logger.info("âœ… OpenAI WS connected (ping disabled)")

        # -- wait session.created ---------------------------------------------
        created = await _expect_json(openai_ws, "session.created", 10)
        if created is None:
            await _abort(ws, "session.created timeout")
            return

        # -- send session.update ----------------------------------------------
        await openai_ws.send(json.dumps({
            "type": "session.update",
            "session": SESSION_CONFIG,
        }))
        logger.info("ğŸ“¤ session.update sent (create_response: False)")

        # wait for session.updated
        updated = await _expect_json(openai_ws, "session.updated", 5)
        if updated:
            logger.info("âœ… session.updated received")

        # ğŸŒŸ å…±æœ‰çŠ¶æ…‹: åŠ©æ‰‹ãŒè©±ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹
        assistant_speaking = asyncio.Event()

        # --------------------------- start proxy tasks -----------------------
        await asyncio.gather(
            _unity_to_openai(ws, openai_ws, assistant_speaking),
            _openai_to_unity(ws, openai_ws, assistant_speaking),
            return_exceptions=True,
        )

    except WebSocketDisconnect:
        logger.info("Unity disconnected")
    except InvalidStatusCode as exc:
        await _abort(ws, f"OpenAI WS status {exc.status_code}")
    except Exception as exc:  # noqa: BLE001
        logger.exception("relay fatal: %s", exc)
        await _abort(ws, "internal error")
    finally:
        if openai_ws is not None:
            await _safe_close(openai_ws)
        logger.info("session ended: %s", id(ws))

# -----------------------------------------------------------------------------
# Task 1: Unity â†’ OpenAIï¼ˆãƒãƒ¼ã‚¸ã‚¤ãƒ³å¯¾å¿œï¼‰
# -----------------------------------------------------------------------------

async def _unity_to_openai(
    unity_ws: WebSocket, 
    openai_ws: websockets.WebSocketClientProtocol,
    assistant_speaking: asyncio.Event
) -> None:
    """PCM16 chunks â†’ base64 & append/commit with barge-in support"""
    idx = 0
    user_speaking = False
    has_active_response = False  # å¿œç­”ç”Ÿæˆä¸­ãƒ•ãƒ©ã‚°
    audio_buffer_size = 0  # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºè¿½è·¡
    
    async for pcm in unity_ws.iter_bytes():
        if not pcm:
            continue
        
        # éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if idx == 0:
            import struct
            try:
                samples = struct.unpack(f"{len(pcm)//2}h", pcm)
                max_amplitude = max(abs(s) for s in samples) if samples else 0
                if max_amplitude > 100:  # é–¾å€¤
                    logger.debug(f"ğŸ¤ éŸ³å£°æ¤œå‡º: æŒ¯å¹… {max_amplitude}")
            except:
                pass
        
        # ğŸŒŸ ãƒãƒ¼ã‚¸ã‚¤ãƒ³å‡¦ç†: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—å§‹ã‚ãŸç¬é–“
        if idx == 0 and assistant_speaking.is_set():
            # AIãŒè©±ã—ã¦ã„ã‚‹æœ€ä¸­ãªã‚‰ä¸­æ–­
            await openai_ws.send(json.dumps({"type": "response.cancel"}))
            logger.info("ğŸ›‘ User interrupted - cancelling AI response")
            assistant_speaking.clear()
            has_active_response = False
        
        idx += 1
        audio_buffer_size += len(pcm)
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’é€ä¿¡
        await openai_ws.send(json.dumps({
            "type": "input_audio_buffer.append",
            "audio": base64.b64encode(pcm).decode(),
        }))
        
        # 20ãƒãƒ£ãƒ³ã‚¯ï¼ˆç´„1ç§’ï¼‰ã”ã¨ã«ã‚³ãƒŸãƒƒãƒˆï¼†å¿œç­”ç”Ÿæˆ
        if idx >= 20 and not has_active_response:
            # ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            logger.info(f"ğŸ“Š éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {audio_buffer_size} bytes ({audio_buffer_size/32000:.2f}ç§’)")
            
            await openai_ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
            
            # æ—¢ã«å¿œç­”ç”Ÿæˆä¸­ã§ãªã„å ´åˆã®ã¿ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            if not assistant_speaking.is_set():
                await openai_ws.send(json.dumps({
                    "type": "response.create",
                    "response": {
                        "modalities": ["audio", "text"],
                        "instructions": "ã‚ãªãŸã¯è¦ªåˆ‡ãªåŒ»ç™‚ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚",
                        "voice": "alloy",  # æ˜ç¤ºçš„ã«éŸ³å£°æŒ‡å®š
                        "temperature": 0.7,
                    },
                }))
                has_active_response = True
                logger.info(f"ğŸ“¤ Committed {idx} chunks & requested response")
            else:
                logger.info(f"ğŸ“¤ Committed {idx} chunks (response already active)")
            
            idx = 0
            audio_buffer_size = 0

# -----------------------------------------------------------------------------
# Task 2: OpenAI â†’ Unity
# -----------------------------------------------------------------------------

async def _openai_to_unity(
    unity_ws: WebSocket, 
    openai_ws: websockets.WebSocketClientProtocol,
    assistant_speaking: asyncio.Event
) -> None:
    """OpenAI events â†’ Unity with speaking state tracking"""
    
    async for m in openai_ws:
        if isinstance(m, str):
            try:
                d: dict[str, Any] = json.loads(m)
            except json.JSONDecodeError:
                continue
                
            t = d.get("type", "?")
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®è»¢é€
            if t == "response.audio.delta":
                b64 = d.get("delta", "")
                if b64:
                    await unity_ws.send_bytes(base64.b64decode(b64))
                    # éŸ³å£°å†ç”Ÿé–‹å§‹ã‚’è¨˜éŒ²
                    if not assistant_speaking.is_set():
                        assistant_speaking.set()
                        logger.info("ğŸ”Š Assistant started speaking")
                        
            # å¿œç­”å®Œäº†
            elif t == "response.done":
                assistant_speaking.clear()
                logger.info("âœ… Assistant finished speaking")
                
            # éŸ³å£°èªè­˜çµæœ
            elif t == "conversation.item.input_audio_transcription.completed":
                transcript = d.get("transcript", "")
                if transcript:
                    logger.info(f"ğŸ“ User said: {transcript}")
                    
            # AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆ
            elif t == "response.audio_transcript.delta":
                transcript = d.get("delta", "")
                if transcript:
                    logger.info(f"ğŸ¤– AI response: {transcript}")
                    
            # éŸ³å£°æ¤œå‡ºã‚¤ãƒ™ãƒ³ãƒˆ
            elif t == "input_audio_buffer.speech_started":
                logger.debug("ğŸ™ï¸ Speech detected")
            elif t == "input_audio_buffer.speech_stopped":
                logger.debug("ğŸ™ï¸ Speech ended")
                
            # Function calling
            elif t == "response.function_call_arguments.done":
                await handle_function(d)
                
            # ã‚¨ãƒ©ãƒ¼
            elif t.startswith("error"):
                logger.error(f"âŒ OpenAI error: {d}")
                
            # ãƒ‡ãƒãƒƒã‚°ç”¨
            else:
                logger.debug(f"ğŸ“¨ OpenAI event: {t}")

# -----------------------------------------------------------------------------
# Utilities
# -----------------------------------------------------------------------------

async def _expect_json(ws: websockets.WebSocketClientProtocol, typ: str, timeout: float):
    try:
        raw = await asyncio.wait_for(ws.recv(), timeout)
        if isinstance(raw, str):
            data = json.loads(raw)
            if data.get("type") == typ:
                return data
    except asyncio.TimeoutError:
        pass
    return None

async def _abort(unity_ws: WebSocket, reason: str):
    logger.error("abort: %s", reason)
    try:
        await unity_ws.close(code=1011, reason=reason)
    except Exception:
        pass

async def _safe_close(ws: websockets.WebSocketClientProtocol):
    try:
        await ws.close()
    except Exception:
        pass

# -----------------------------------------------------------------------------

@router.get("/health")
async def health():
    return {
        "status": "healthy",
        "model": MODEL_NAME,
        "mode": "manual_control",
        "create_response": "false",
        "barge_in": "enabled",
        "url": get_websocket_url(),
    }

