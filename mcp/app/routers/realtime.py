# mcp/app/routers/realtime.py - æ–¹å¼Bæœ€çµ‚ä¿®æ­£ç‰ˆï¼ˆéŸ³å£°é‡è¤‡å•é¡Œè§£æ±ºï¼‰

"""Unity â‡† OpenAI Realtime Audio API - æ–¹å¼Bï¼ˆæ‰‹å‹•åˆ¶å¾¡ï¼‹ãƒãƒ¼ã‚¸ã‚¤ãƒ³ï¼‰
----------------------------------------------------------------
ä¿®æ­£å†…å®¹:
1. éŸ³å£°é‡è¤‡ã®é˜²æ­¢: response_in_progressãƒ•ãƒ©ã‚°ã§å³å¯†ã«ç®¡ç†
2. ç©ºãƒãƒƒãƒ•ã‚¡ã‚¨ãƒ©ãƒ¼ã®è§£æ¶ˆ: ç„¡éŸ³æ¤œå‡ºã‚’æ”¹å–„
3. ãƒãƒ¼ã‚¸ã‚¤ãƒ³æ”¹å–„: å¿œç­”ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æœ€é©åŒ–
"""

from __future__ import annotations

import asyncio
import base64
import json
import logging
from typing import Any

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
import websockets
from websockets.exceptions import ConnectionClosed, WebSocketException, InvalidStatusCode

from ..core.config import (
    get_websocket_url,
    OPENAI_API_KEY,
    SESSION_CONFIG,
    MODEL_NAME,
)
from ..services.function import handle_function

logger = logging.getLogger(__name__)
router = APIRouter()

# -----------------------------------------------------------------------------
# WebSocket relay
# -----------------------------------------------------------------------------

@router.websocket("/ws/audio")
async def relay(ws: WebSocket) -> None:  # noqa: C901
    """Unity â†” FastAPI â†” OpenAI realtime audio relay"""
    await ws.accept()
    logger.info("Unity WS connected: %s", id(ws))

    url = get_websocket_url()
    extra_headers = [
        ("Authorization", f"Bearer {OPENAI_API_KEY}"),
        ("OpenAI-Beta", "realtime=v1"),
    ]

    openai_ws: websockets.WebSocketClientProtocol | None = None

    try:
        # --------------------------- connect to OpenAI ------------------------
        openai_ws = await websockets.connect(
            url,
            extra_headers=extra_headers,
            ping_interval=None,
            ping_timeout=None,
            close_timeout=10,
        )
        logger.info("âœ… OpenAI WS connected (ping disabled)")

        # -- wait session.created ---------------------------------------------
        created = await _expect_json(openai_ws, "session.created", 10)
        if created is None:
            await _abort(ws, "session.created timeout")
            return

        # -- send session.update ----------------------------------------------
        await openai_ws.send(json.dumps({
            "type": "session.update",
            "session": SESSION_CONFIG,
        }))
        logger.info("ğŸ“¤ session.update sent (create_response: False)")

        # wait for session.updated
        updated = await _expect_json(openai_ws, "session.updated", 5)
        if updated:
            logger.info("âœ… session.updated received")

        # ğŸŒŸ å…±æœ‰çŠ¶æ…‹
        assistant_speaking = asyncio.Event()
        response_in_progress = asyncio.Event()  # å¿œç­”ç”Ÿæˆä¸­ãƒ•ãƒ©ã‚°

        # --------------------------- start proxy tasks -----------------------
        await asyncio.gather(
            _unity_to_openai(ws, openai_ws, assistant_speaking, response_in_progress),
            _openai_to_unity(ws, openai_ws, assistant_speaking, response_in_progress),
            return_exceptions=True,
        )

    except WebSocketDisconnect:
        logger.info("Unity disconnected")
    except InvalidStatusCode as exc:
        await _abort(ws, f"OpenAI WS status {exc.status_code}")
    except Exception as exc:  # noqa: BLE001
        logger.exception("relay fatal: %s", exc)
        await _abort(ws, "internal error")
    finally:
        if openai_ws is not None:
            await _safe_close(openai_ws)
        logger.info("session ended: %s", id(ws))

# -----------------------------------------------------------------------------
# Task 1: Unity â†’ OpenAIï¼ˆéŸ³å£°é‡è¤‡é˜²æ­¢ç‰ˆï¼‰
# -----------------------------------------------------------------------------

async def _unity_to_openai(
    unity_ws: WebSocket, 
    openai_ws: websockets.WebSocketClientProtocol,
    assistant_speaking: asyncio.Event,
    response_in_progress: asyncio.Event
) -> None:
    """PCM16 chunks â†’ base64 & append/commit with duplicate prevention"""
    idx = 0
    audio_buffer_size = 0
    has_voice = False  # å®Ÿéš›ã®éŸ³å£°ãŒã‚ã‚‹ã‹
    
    async for pcm in unity_ws.iter_bytes():
        if not pcm:
            continue
        
        # éŸ³å£°ãƒ¬ãƒ™ãƒ«ãƒã‚§ãƒƒã‚¯ï¼ˆç„¡éŸ³æ¤œå‡ºï¼‰
        import struct
        try:
            samples = struct.unpack(f"{len(pcm)//2}h", pcm)
            max_amplitude = max(abs(s) for s in samples) if samples else 0
            # ã‚ˆã‚Šé«˜ã„é–¾å€¤ã§ç„¡éŸ³ã‚’åˆ¤å®š
            if max_amplitude > 500:  # é–¾å€¤ã‚’ä¸Šã’ã‚‹
                has_voice = True
                logger.debug(f"ğŸ¤ éŸ³å£°æ¤œå‡º: æŒ¯å¹… {max_amplitude}")
        except:
            pass
        
        # ãƒãƒ¼ã‚¸ã‚¤ãƒ³å‡¦ç†
        if idx == 0 and assistant_speaking.is_set():
            await openai_ws.send(json.dumps({"type": "response.cancel"}))
            logger.info("ğŸ›‘ User interrupted - cancelling AI response")
            assistant_speaking.clear()
            response_in_progress.clear()
        
        # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        await openai_ws.send(json.dumps({
            "type": "input_audio_buffer.append",
            "audio": base64.b64encode(pcm).decode(),
        }))
        
        idx += 1
        audio_buffer_size += len(pcm)
        
        # 20ãƒãƒ£ãƒ³ã‚¯ï¼ˆç´„1ç§’ï¼‰ã”ã¨ã«å‡¦ç†
        if idx >= 20:
            logger.info(f"ğŸ“Š éŸ³å£°ãƒãƒƒãƒ•ã‚¡: {audio_buffer_size} bytes, éŸ³å£°ã‚ã‚Š: {has_voice}")
            
            # éŸ³å£°ãŒã‚ã‚‹å ´åˆã®ã¿ã‚³ãƒŸãƒƒãƒˆ
            if has_voice and audio_buffer_size > 3200:  # 2ãƒãƒ£ãƒ³ã‚¯åˆ†ä»¥ä¸Š
                await openai_ws.send(json.dumps({"type": "input_audio_buffer.commit"}))
                
                # å¿œç­”ç”Ÿæˆä¸­ã§ãªã„å ´åˆã®ã¿ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                if not response_in_progress.is_set() and not assistant_speaking.is_set():
                    response_in_progress.set()  # ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
                    await openai_ws.send(json.dumps({
                        "type": "response.create",
                        "response": {
                            "modalities": ["audio", "text"],
                            "instructions": "ã‚ãªãŸã¯è¦ªåˆ‡ãªåŒ»ç™‚ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ç°¡æ½”ã«å¿œç­”ã—ã¦ãã ã•ã„ã€‚",
                            "voice": "alloy",
                            "temperature": 0.7,
                        },
                    }))
                    logger.info("ğŸ“¤ å¿œç­”ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡")
                else:
                    logger.info("ğŸ“¤ ã‚³ãƒŸãƒƒãƒˆã®ã¿ï¼ˆå¿œç­”ç”Ÿæˆä¸­ï¼‰")
            else:
                # ç„¡éŸ³ã®å ´åˆã¯ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
                await openai_ws.send(json.dumps({"type": "input_audio_buffer.clear"}))
                logger.info("ğŸ”‡ ç„¡éŸ³ã®ãŸã‚ãƒãƒƒãƒ•ã‚¡ã‚¯ãƒªã‚¢")
            
            # ãƒªã‚»ãƒƒãƒˆ
            idx = 0
            audio_buffer_size = 0
            has_voice = False

# -----------------------------------------------------------------------------
# Task 2: OpenAI â†’ Unityï¼ˆå¿œç­”ç®¡ç†æ”¹å–„ç‰ˆï¼‰
# -----------------------------------------------------------------------------

async def _openai_to_unity(
    unity_ws: WebSocket, 
    openai_ws: websockets.WebSocketClientProtocol,
    assistant_speaking: asyncio.Event,
    response_in_progress: asyncio.Event
) -> None:
    """OpenAI events â†’ Unity with improved response management"""
    
    async for m in openai_ws:
        if isinstance(m, str):
            try:
                d: dict[str, Any] = json.loads(m)
            except json.JSONDecodeError:
                continue
                
            t = d.get("type", "?")
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®è»¢é€
            if t == "response.audio.delta":
                delta = d.get("delta", "")
                if delta:
                    try:
                        audio_bytes = base64.b64decode(delta)
                        await unity_ws.send_bytes(audio_bytes)
                        # åˆå›ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã§è©±ã—å§‹ã‚ã‚’è¨˜éŒ²
                        if not assistant_speaking.is_set():
                            assistant_speaking.set()
                            logger.info("ğŸ”Š Assistant started speaking")
                            logger.info(f"ğŸ“¤ æœ€åˆã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡: {len(audio_bytes)} bytes")
                    except Exception as e:
                        logger.error(f"âŒ éŸ³å£°ãƒ‡ãƒ¼ã‚¿é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
                        
            # å¿œç­”å®Œäº†
            elif t == "response.done":
                assistant_speaking.clear()
                response_in_progress.clear()  # ãƒ•ãƒ©ã‚°ã‚’ã‚¯ãƒªã‚¢
                logger.info("âœ… Assistant finished speaking")
                
            # å¿œç­”ã‚­ãƒ£ãƒ³ã‚»ãƒ«å®Œäº†
            elif t == "response.cancelled":
                assistant_speaking.clear()
                response_in_progress.clear()
                logger.info("âŒ Response cancelled")
                
            # éŸ³å£°èªè­˜çµæœ
            elif t == "conversation.item.input_audio_transcription.completed":
                transcript = d.get("transcript", "")
                if transcript:
                    logger.info(f"ğŸ“ User said: {transcript}")
                    
            # AIå¿œç­”ã®ãƒ†ã‚­ã‚¹ãƒˆ
            elif t == "response.audio_transcript.delta":
                transcript = d.get("delta", "")
                if transcript:
                    logger.info(f"ğŸ¤– AI: {transcript}")
                    
            # éŸ³å£°æ¤œå‡ºã‚¤ãƒ™ãƒ³ãƒˆ
            elif t == "input_audio_buffer.speech_started":
                logger.debug("ğŸ™ï¸ Speech detected")
            elif t == "input_audio_buffer.speech_stopped":
                logger.debug("ğŸ™ï¸ Speech ended")
                
            # Function calling
            elif t == "response.function_call_arguments.done":
                await handle_function(d)
                
            # ã‚¨ãƒ©ãƒ¼
            elif t.startswith("error"):
                error_code = d.get("error", {}).get("code", "")
                # ç©ºãƒãƒƒãƒ•ã‚¡ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                if error_code != "input_audio_buffer_commit_empty":
                    logger.error(f"âŒ OpenAI error: {d}")
                
            # ãƒ‡ãƒãƒƒã‚°ç”¨
            else:
                if t not in ["session.created", "session.updated", "response.created"]:
                    logger.debug(f"ğŸ“¨ OpenAI event: {t}")

# -----------------------------------------------------------------------------
# Utilities
# -----------------------------------------------------------------------------

async def _expect_json(ws: websockets.WebSocketClientProtocol, typ: str, timeout: float):
    try:
        raw = await asyncio.wait_for(ws.recv(), timeout)
        if isinstance(raw, str):
            data = json.loads(raw)
            if data.get("type") == typ:
                return data
    except asyncio.TimeoutError:
        pass
    return None

async def _abort(unity_ws: WebSocket, reason: str):
    logger.error("abort: %s", reason)
    try:
        await unity_ws.close(code=1011, reason=reason)
    except Exception:
        pass

async def _safe_close(ws: websockets.WebSocketClientProtocol):
    try:
        await ws.close()
    except Exception:
        pass

# -----------------------------------------------------------------------------

@router.get("/health")
async def health():
    return {
        "status": "healthy",
        "model": MODEL_NAME,
        "mode": "manual_control_v2",
        "create_response": "false",
        "barge_in": "enabled",
        "duplicate_prevention": "enabled",
        "url": get_websocket_url(),
    }
