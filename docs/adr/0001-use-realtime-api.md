# ADR-0001: OpenAI Realtime API + FastAPIアーキテクチャの採用

**日付**: 2025-05-26  
**ステータス**: 採用済み  
**決定者**: 開発チーム

## 🎯 状況
Virtual AI Doctorで**300ms以下の低レイテンシ音声応答**を実現する必要がある。従来のWhisper + ChatGPT + TTSパイプラインでは、複数APIの連携によりレイテンシが1000ms以上となってしまう問題があった。

## 🤔 考慮した選択肢

### 選択肢A: 従来のパイプライン (Whisper + ChatGPT + TTS)
- **メリット**: 各APIが安定、豊富な事例
- **デメリット**: 複数API呼び出しで高レイテンシ（1000ms+）

### 選択肢B: OpenAI Realtime API
- **メリット**: 単一API、低レイテンシ（~300ms）、音声の感情表現保持
- **デメリット**: 新しいAPI、事例が少ない

### 選択肢C: Azure Speech Services + Custom LLM
- **メリット**: 企業向けサポート
- **デメリット**: 複雑なセットアップ、高コスト

## ✅ 決定
**OpenAI Realtime API + FastAPI**を採用

### 理由
1. **レイテンシ要件**: 目標300ms以下を満たす唯一の選択肢
2. **統合性**: 音声認識→推論→音声合成が一つのAPIで完結
3. **音声品質**: 感情やトーンの自然な表現が可能
4. **拡張性**: Function Callingでメディカル検索等の機能追加が容易
5. **開発効率**: WebSocketベースのシンプルなアーキテクチャ

## 🏗 実装方針
- **FastAPI**: WebSocketサーバー、UnityクライアントのRelay役
- **MCP構造**: 将来のGraph AI連携を見据えた拡張可能設計
- **Function Router**: `function_call`を受信→対応ハンドラー呼び出し

## 📊 結果
- ✅ 音声応答レイテンシ: ~250ms（目標達成）
- ✅ 音声品質: 自然な会話感
- ✅ 開発速度: MVP完成まで1週間

## 🔄 見直し条件
- Realtime APIの利用料金が想定の3倍を超えた場合
- レイテンシが500ms以上に劣化した場合
- より低コストで同等性能の選択肢が登場した場合
